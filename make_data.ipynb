{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cooltools\n",
    "import cooler\n",
    "import cooltools.lib.plotting\n",
    "from matplotlib.ticker import EngFormatter\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import csv\n",
    "import pysam \n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv_file(clr,ref,window=512,occupancy_p=.6,filename=\"./data/hic_sequences.csv\"):\n",
    "    fields=[\"name\",\"start\",\"end\"]\n",
    "    rows=[]\n",
    "    for chrome_name,chrome_size in zip(clr.chromnames[:1],list(clr.chromsizes)[:1]):\n",
    "        for i in range(0,chrome_size-window*clr.binsize,window*clr.binsize):\n",
    "            try :\n",
    "                ref.fetch(chrome_name,i,min(i+window*clr.binsize,chrome_size-1))\n",
    "                mat=clr.matrix(balance=False).fetch((chrome_name,i,min(i+window*clr.binsize,chrome_size-1)))\n",
    "                diagonal=np.diag(mat)\n",
    "                percentage_filled=np.sum((diagonal!=0))/diagonal.shape[0]\n",
    "                if percentage_filled>occupancy_p:\n",
    "                    rows.append([chrome_name,i,min(i+window*clr.binsize,chrome_size-1)])\n",
    "            except:\n",
    "                print(f\"chromosome not found {chrome_name}\")\n",
    "\n",
    "    with open(filename, 'w') as csvfile:  \n",
    "        # creating a csv writer object  \n",
    "        csvwriter = csv.writer(csvfile)  \n",
    "        \n",
    "        # writing the fields  \n",
    "        csvwriter.writerow(fields)  \n",
    "        \n",
    "        # writing the data rows  \n",
    "        csvwriter.writerows(rows) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl = cooler.Cooler('./data/coolers/H1hESC_hg38_4DNFI1O6IL1Q.mapq_30.2048.cool')\n",
    "ref = pysam.FastaFile('./data/hg38.ml.fa')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_csv_file(ctrl,ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateData():\n",
    "    def __init__(self, file,fasta,cool,root_dir=\"./\", transform=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            file (string): Path to the file with annotations.\n",
    "            root_dir (string): Directory with all the tfr files.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        # self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        super().__init__()\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        # to store dictionary for genomic data\n",
    "        self.df_frame=pd.read_csv(file)\n",
    "        self.transform=transform\n",
    "        self.fasta=fasta\n",
    "        self.cooler=cool\n",
    "        self.data_set_X,self.data_set_Y=[],[]\n",
    "        for index, row in self.df_frame.iterrows():\n",
    "            curr=row\n",
    "            X=self.one_hot_enc(self.fasta.fetch(curr[\"name\"],curr[\"start\"],curr[\"end\"]))\n",
    "            y=self.flatten(self.cooler.matrix(balance=False).fetch((curr[\"name\"],curr[\"start\"],curr[\"end\"]))[32:-32,32:-32])\n",
    "            self.data_set_X.append(X),self.data_set_Y.append(y)\n",
    "    def one_hot_enc(self,seq):\n",
    "        ans=[]\n",
    "        for i in seq:\n",
    "            if i ==\"A\":\n",
    "                ans.append([1.0,0,0,0,0])\n",
    "            elif i ==\"T\":\n",
    "                ans.append([0,1.0,0,0,0])\n",
    "            elif i==\"G\":\n",
    "                ans.append([0,0,1.0,0,0])\n",
    "            elif i==\"C\":\n",
    "                ans.append([0,0,0,1.0,0])\n",
    "            else:\n",
    "                ans.append([0,0,0,0,1.0])\n",
    "\n",
    "        return np.array(ans).T\n",
    "    def flatten(self,mat):\n",
    "        return torch.tensor(mat[np.triu_indices(mat.shape[0],2)]).unsqueeze(-1)\n",
    "    def K(self,p,q,sigma=1):\n",
    "        return np.exp(-((p[0]-q[0])**2+(p[1]-q[1])**2)**.5/(2*sigma**2))\n",
    "    def cal_value_l(self,p,b,mat,sigma=10):\n",
    "        val,weight=0,0\n",
    "        for i in range(max(0,p[0]-b),min(mat.shape[0],p[0])):\n",
    "            for j in range(max(0,p[1]-b),min(mat.shape[1],p[1])):\n",
    "                w=self.K(p,[i,j],sigma)\n",
    "                val+=mat[i,j]*w\n",
    "                weight+=w\n",
    "        if weight==0:\n",
    "            return mat[p[0]-1][p[1]-1]\n",
    "        return val/weight\n",
    "    def cal_value_r(self,p,b,mat,sigma=10):\n",
    "        val,weight=0,0\n",
    "        for i in range(max(0,p[0]),min(mat.shape[0],p[0]+b)):\n",
    "            for j in range(max(0,p[1]),min(mat.shape[1],p[1]+b)):\n",
    "                w=self.K(p,[i,j],sigma)\n",
    "                val+=mat[i,j]*w\n",
    "                weight+=w\n",
    "        if weight==0:\n",
    "            return mat[p[0]+1][p[1]+1]\n",
    "        return val/weight\n",
    "    def fill_mat(self,mat,b=5,sigma=30):\n",
    "        # mat=np.array(m, copy=True)\n",
    "        d=np.diag(mat)\n",
    "        for i in range(mat.shape[0]):\n",
    "            if d[i]==0:\n",
    "                for j in range(i,mat.shape[0]):\n",
    "                    mat[i,j]=self.cal_value_l([i,j],b,mat,sigma)\n",
    "                for j in range(i,-1,-1):\n",
    "                    mat[i,j]=self.cal_value_l([i,j],b,mat,sigma)\n",
    "                for j in range(i,mat.shape[1]):\n",
    "                    mat[j,i]=self.cal_value_l([j,i],b,mat,sigma)\n",
    "                for j in range(i,-1,-1):\n",
    "                    mat[j,i]=self.cal_value_l([j,i],b,mat,sigma)\n",
    "        for i in range(mat.shape[0]-1,-1,-1):\n",
    "            if d[i]==0:\n",
    "                for j in range(i,mat.shape[0]):\n",
    "                    mat[i,j]=max(mat[i,j],self.cal_value_r([i,j],b,mat,sigma))\n",
    "                for j in range(i,-1,-1):\n",
    "                    mat[i,j]=max(mat[i,j],self.cal_value_r([i,j],b,mat,sigma))\n",
    "                for j in range(i,mat.shape[1]):\n",
    "                    mat[j,i]=max(mat[j,i],self.cal_value_r([j,i],b,mat,sigma))\n",
    "                for j in range(i,-1,-1):\n",
    "                    mat[j,i]=max(mat[j,i],self.cal_value_r([j,i],b,mat,sigma))\n",
    "        return mat\n",
    "    def __call__(self):\n",
    "        return (self.data_set_X,self.data_set_Y)\n",
    "class TorchDataset(Dataset):\n",
    "    def __init__(self,data,transform=None):\n",
    "        super().__init__()\n",
    "        self.transform=transform\n",
    "        self.data=data\n",
    "    def __len__(self):\n",
    "        return len(self.data[0])\n",
    "    def __getitem__(self, idx):\n",
    "        X,y=self.data[0][idx],self.data[1][idx]\n",
    "        sample=(X,y)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=CreateData(\"./hic_sequences.csv\",ref,ctrl)\n",
    "dataset = TorchDataset(C())\n",
    "train,test=torch.utils.data.random_split(dataset,[int(0.9*len(dataset)),len(dataset)-int(0.90*len(dataset))], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train,\"./data/train.pth\")\n",
    "torch.save(test,\"./data/test.pth\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
